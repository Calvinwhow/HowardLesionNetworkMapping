{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Notebook\n",
    "\n",
    "### Authors: William Drew, Alexander Cohen, Joey Hsu, Louis Soussand, Christopher Lin\n",
    "\n",
    "## Last updated: June 7, 2022\n",
    "\n",
    "### Notes:\n",
    "- This notebook requires the NIMLAB Python 3 environment as a kernel and FSL on your path. Directions at: (https://github.com/nimlab/software_env)\n",
    "- I realize that we are using 'Lesion' Network Mapping to apply to DBS lead locations, meta-analytic foci, etc... but for the sake of clarity, and not having to just say seed all the time, I've used the word Lesion to mean Lesions/Masks/Foci/Seeds interchangably."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Introduction\n",
    "### This is the preprocessing notebook, which is used to generate **functional and structural connectivity maps** from various **brain regions of interest**.\n",
    "\n",
    "### This notebook is capable of processing input from:\n",
    "- **Volume-space Nifti ROIs**\n",
    "    - Examples:\n",
    "        - Lesion masks\n",
    "        - Brain coordinates\n",
    "        - TMS cones\n",
    "        - DBS Lead locations\n",
    "        - VTAs from DBS\n",
    "        - and so much more!\n",
    "- **Surface-space Gifti ROIs**\n",
    "    - Examples:\n",
    "        - White matter atrophy maps\n",
    "        - White matter growth maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 0. What do you want to name your Preprocessed Dataset?\n",
    "\n",
    "Provide a Dataset, i.e., Project Name\n",
    "\n",
    "This will also be the name of a sub-directory, in the same directory as the notebook, that will contain the following:\n",
    "1. a copy of the original lesions in `./inputs`,\n",
    "2. a cleaned version of the lesions in `./sub-*/roi`,\n",
    "3. a copy of your Functional/Structural Connectivity Maps in `./sub-*/connectivity`,\n",
    "4. a `./README.md` that notes the original location of the seeds and which connectomes were used, and\n",
    "5. a `./ProjectName.csv` that contains paths to the imaging files that can be used in later analyses, bypassing the XNAT archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the project name and folder where you want the output files to go:\n",
    "\n",
    "# EXAMPLE preprocess_folder = \"/PHShome/wd957/Preprocessing\"\n",
    "# EXAMPLE project_name = \"Prosopagnosia_lesions\"\n",
    "# This will create a project folder \"/PHShome/wd957/Preprocessing/Prosopagnosia_lesions\"\n",
    "\n",
    "preprocess_folder = \"\" # If left blank, will create dataset folder in same directory as notebook\n",
    "project_name = \"\" # Enter your chosen project name here\n",
    "\n",
    "########################################################################\n",
    "\n",
    "## Packages:\n",
    "import os\n",
    "from glob import glob\n",
    "from natsort import natsorted\n",
    "from nimlab import preprocessing\n",
    "from nimlab import software as sf\n",
    "env = preprocessing.init_env(project_name, preprocess_folder)\n",
    "use_datalad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we do ANYTHING ELSE, rename this notebook to match your chosen Dataset Name:\n",
    "Example: `1_Preprocessing_LesionQA_fcSurfBcbLqtGen_nimtrack.ipynb` --> `Prosopagnosia_lesions_1_Preprocessing_LesionQA_fcSurfBcbLqtGen_nimtrack.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Input/Output Setup\n",
    "\n",
    "## 1. First, provide your email address and User ID for future reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your email address and User ID here in quotes:\n",
    "env[\"creator_email\"] = \"wdrew@bwh.harvard.edu\"\n",
    "env[\"cluster_user\"] = \"wd957\"\n",
    "\n",
    "preprocessing.save_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 2. Where are your lesions?\n",
    "**NOTE:** only run **ONE** of the following two cells depending on how you have stored your lesion files:\n",
    "- If you have collected all of your lesions in one folder, choose **Option 1**\n",
    "- If you have organzied your lesions in a BIDS/derivatives folder, choose **Option 2**\n",
    "\n",
    "### Option One allows for both volume-space and surface-space lesions.\n",
    "\n",
    "- **NOTE:** ROI files of only one type (volume or surface) are permitted. If you wish to process both volume and surface ROIs, please use two notebooks, one for volume ROIs and one for surface ROIs. \n",
    "\n",
    "- **NOTE:** Surface files (.gii) **must** be prefixed with `lh.` or `rh.` to indicate hemisphere. Filenames between two hemisphere files **must** be identical.\n",
    "\n",
    "    - **Example**: \n",
    "        > /path/to/lh.subject1.gii, /path/to/rh.subject1.gii\n",
    "\n",
    "        > /path/to/lh.subject2.gii, /path/to/rh.subject2.gii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# OPTION ONE - If you have collected all of your lesions in one folder:\n",
    "\n",
    "env[\"input_folder\"] = ''\n",
    "# EXAMPLE input_folder = \"/PHShome/wd957/test_lesions/2mm\"\n",
    "\n",
    "env[\"lesion_type\"], env[\"lesions\"] = preprocessing.load_rois(env[\"input_folder\"])\n",
    "preprocessing.save_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # OPTION TWO - If you have organized your lesions in a BIDS/derivatives folder:\n",
    "# env[\"lesions\"] = {}\n",
    "# env[\"input_folder\"] = 'BIDS_dir'\n",
    "# # EXAMPLE env[\"input_folder\"] = \"/Users/alex/data/lesions/Leigh_bids\"\n",
    "\n",
    "# lesion_files = natsorted(glob(os.path.join(input_folder, \"derivatives/lesions/sub*/sub-*space-MNI152NLin2009cAsym_desc-lesion_mask.nii.gz\")))\n",
    "# for vol_file in lesion_files:\n",
    "#     subject_name = os.path.basename(vol_file).split(\"sub-\")[1].split(\"space-MNI152NLin2009cAsym_desc-lesion_mask.nii.gz\")[0]\n",
    "#     env[\"lesions\"][subject_name] = vol_file\n",
    "# env[\"lesion_type\"] = \"volume\"\n",
    "# preprocessing.save_env(env)\n",
    "# print(\"I found\", len(lesion_files), \"lesions files:\")\n",
    "# lesion_files[0:5]  # show me the first five found to verify the path is correct\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 3. Which Functional/Structural Connectivity Pipelines would you like to run?\n",
    "\n",
    "There are two **functional** connectivity pipelines available:\n",
    "- Volume-space functional connectivity with `connectome_quick`\n",
    "- Surface-space functional connectivity with `connectome_quick`\n",
    "\n",
    "There are two **structural** connectivity pipelines available:\n",
    "- Volume-space structural connectivity with `BCB Toolkit`\n",
    "- Volume-space structural connectivity with `Lesion Quantification Toolkit`\n",
    "\n",
    "### If at any point you would like to reset your chosen pipelines, run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to reset your chosen pipelines\n",
    "env[\"connectivity_analyses\"] = []\n",
    "\n",
    "preprocessing.save_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a. Volume-space Functional Connectivity with `connectome_quick`\n",
    "\n",
    "**NOTE:** the _directory_ will vary depending on which machine you are logged into. \n",
    "\n",
    "On ERISOne, `connectome_dir` should be `/data/nimlab/connectome_npy`\n",
    "\n",
    "### Select a Functional Volume-space Connectome\n",
    "The available volume-space connectomes are\n",
    "\n",
    "- `GSP1000_MF`: (Default) Gender-balanced GSP 1000\n",
    "- `yeo1000_dil`: Yeo 1000 connectome (Deprecated March 2023)\n",
    "- `GSP1000`: GSP 1000 connectome processed with the CBIG pipeline (same pipeline as Yeo)\n",
    "- `GSP346_F`: Female-only GSP 1000 with 346 subjects\n",
    "- `GSP346_M`: Male-only GSP 1000 with 346 subjects\n",
    "- `GSP500_F`: Female-only GSP 1000 with 500 subjects\n",
    "- `GSP500_M`: Male-only GSP 1000 with 500 subjects\n",
    "\n",
    "**NOTE**: If you are using surface-space ROIs and running the volume-space connectome, you **MUST** select the `GSP1000_MF` connectome.\n",
    "\n",
    "### If you do not want to generate Functional Volume-space Connectivity maps, leave `connectome_name` blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the connectome to use to make fc Maps from the lesion/seed locations:\n",
    "env[\"connectome_name\"] = \"\"\n",
    "\n",
    "# If you are using any of the connectomes produced after fall 2019, dil should be the correct mask.\n",
    "# If the connectome is the original one used with connectome.sh, then the mask should be 222\n",
    "# This variable is for metadata only.\n",
    "env[\"connectome_mask\"] = \"dil\"\n",
    "\n",
    "env[\"input_spaces\"], env[\"output_spaces\"], env[\"connectivity_analyses\"] = preprocessing.add_func_pipeline(\n",
    "    env[\"connectivity_analyses\"],\n",
    "    env[\"lesion_type\"],\n",
    "    env[\"input_spaces\"],\n",
    "    env[\"output_spaces\"],\n",
    "    env[\"connectome_name\"],\n",
    "    env[\"connectome_mask\"])\n",
    "\n",
    "preprocessing.save_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b. Surface-space Functional Connectivity with `connectome_quick`\n",
    "### Select a Functional Surface-space Connectome\n",
    "\n",
    "The available surface-space connectomes are\n",
    "\n",
    "- `GSP1000_MF_surf_fs5`: Gender-balanced GSP 1000 in fsaverage 5 space\n",
    "\n",
    "### If you do not want to generate Functional Surface-space Connectivity maps, leave `surf_connectome_name` blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the connectome to use to make fc Maps from the lesion/seed locations:\n",
    "env[\"surf_connectome_name\"] = \"\"\n",
    "\n",
    "# This variable is for metadata only.\n",
    "env[\"surf_connectome_mask\"] = \"fs5\"\n",
    "env[\"input_spaces\"], env[\"output_spaces\"], env[\"connectivity_analyses\"] = preprocessing.add_surf_pipeline(\n",
    "    env[\"connectivity_analyses\"],\n",
    "    env[\"lesion_type\"],\n",
    "    env[\"input_spaces\"],\n",
    "    env[\"output_spaces\"],\n",
    "    env[\"surf_connectome_name\"],\n",
    "    env[\"surf_connectome_mask\"])\n",
    "preprocessing.save_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3c. Volume-space structural connectivity with `BCB Toolkit`\n",
    "\n",
    "The available structural BCB Toolkit connectomes on ERISone are\n",
    "\n",
    "- `Disconnectome7T`: (Default) 178 subject 1mm Dataset from HCP 7T Data\n",
    "- `tracks2mm`: 100 subject 2mm Dataset\n",
    "- `Base10`: 10 subject 1mm Dataset\n",
    "- `Base35`: 35 subject 1mm Dataset\n",
    "\n",
    "### If you do not want to compute structural connectivity with the BCB Toolkit, leave `bcb_connectome_name` blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the connectome to use to make structural disconnection Maps from the lesion/seed locations:\n",
    "env[\"bcb_connectome_name\"] = \"\"\n",
    "\n",
    "# This variable is for metadata only.\n",
    "env[\"bcb_connectome_mask\"] = \"dil\"\n",
    "env[\"input_spaces\"], env[\"output_spaces\"], env[\"connectivity_analyses\"] = preprocessing.add_bcb_pipeline(\n",
    "    env[\"connectivity_analyses\"],\n",
    "    env[\"lesion_type\"],\n",
    "    env[\"input_spaces\"],\n",
    "    env[\"output_spaces\"],\n",
    "    env[\"bcb_connectome_name\"],\n",
    "    env[\"bcb_connectome_mask\"])\n",
    "preprocessing.save_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3d. Volume-space structural connectivity with `Lesion Quantification Toolkit`\n",
    "\n",
    "### Configuration Options for the Lesion Quantification Toolkit:\n",
    "* `connectivity_type`: ('end' or 'pass', Default 'end')\n",
    "\n",
    "    Specifies the criteria for defining structural connections. There are two options: “end”, which defines the connections between two parcels as those streamlines that end in both parcels, or “pass”, which defines the connections between two parcels as those streamlines that either end in or pass through both parcels. “end” is recommended but will produce sparser connectivity matrices.\n",
    "* `sspl_spared_thresh`: (integer 1-100, Default 50)\n",
    "    \n",
    "    Percent spared threshold for computing SSPLs (e.g. 100 means that only fully spared regions will be included in SSPL calculation; 1 means that all regions with at least 1% spared will be included. Default is 50)\n",
    "* `smooth`: (integer, Default 2)\n",
    "\n",
    "    Corresponds to the full-width half-maximum (FWHM) of the smoothing kernel to be applied to the percent disconnection voxel maps. A single value is required (e.g. 2 = 2 FWHM in voxel units; 0 = no smoothing).\n",
    "\n",
    "Available LQT Connectomes are:\n",
    "- `HCP842`\n",
    "\n",
    "### If you do not want to generate structural connectivity maps with the Lesion Quantification Toolkit, leave `lqt_connectome_name` blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave lqt_connectome_name blank if you do not want to run the LQT pipeline\n",
    "env[\"lqt_connectome_name\"] = \"\"\n",
    "\n",
    "env[\"lqt_connectome_mask\"] = \"dil\"\n",
    "# Set Configuration Options for the Lesion Quantification Toolkit\n",
    "env[\"lqt_options\"] = {\"connectivity_type\": 'end',\n",
    "                      \"sspl_spared_thresh\": 50,\n",
    "                      \"smooth\": 2\n",
    "                      }\n",
    "env[\"input_spaces\"], env[\"output_spaces\"], env[\"connectivity_analyses\"] = preprocessing.add_lqt_pipeline(\n",
    "    env[\"connectivity_analyses\"],\n",
    "    env[\"lesion_type\"],\n",
    "    env[\"input_spaces\"],\n",
    "    env[\"output_spaces\"],\n",
    "    env[\"lqt_connectome_name\"],\n",
    "    env[\"lqt_connectome_mask\"])\n",
    "preprocessing.save_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please verify the selected Functional/Structural Connectivity Pipelines below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env[\"vol_spaces\"], env[\"surf_spaces\"], env[\"set_connectivity_analyses\"] = preprocessing.confirm_connectivity_analyses(\n",
    "    env[\"connectivity_analyses\"],\n",
    "    env[\"lesion_type\"],\n",
    "    env[\"input_spaces\"],\n",
    "    env[\"output_spaces\"],\n",
    "    override = False)\n",
    "preprocessing.save_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4. Set up metadata dataframe and rename files to BIDS format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env[\"meta_df\"] = preprocessing.init_meta_df(env[\"lesion_type\"], env[\"lesions\"], env[\"project_path\"], use_datalad)\n",
    "preprocessing.save_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Lesion Barbershop\n",
    "\n",
    "The following cells walk you through the process of doing Quality Assurance on your lesion masks to identify tracing/registration/weird errors in the masks before you generate Functional/Structural Connectivity maps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Make sure the Volume lesion dimensions match the FSL MNI 2mm Template or make sure the Surface atrophy dimensions match the fsaverage5 template and is binary\n",
    "\n",
    "NOTE: Your volume lesions should ALREADY be registered to, or traced in, MNI space. This code just reslicing to 2mm/1mm voxels and makes the shape conform to our standard bounding box.<br>\n",
    "**if your lesions are still in individual space, STOP NOW and do your registration first**.<br>\n",
    "(This repo may be helpful: https://github.com/bchcohenlab/bids_lesion_code)<br>\n",
    "\n",
    "NOTE: Your surface lesions should already be registered to the fsaverage surface space. This code is just reslicing to fsaverage5 space.\n",
    "\n",
    "NOTE: This step may take a long time if starting from surface-space ROIs (~3-4 minutes per ROI).\n",
    "\n",
    "**Instructions**\n",
    "1. If you wish to threshold your images, set `env[\"doThreshold\"] = True`.\n",
    "2. If you wish to binarize your images, set `env[\"binarize\"] = True`. You must also set `env[\"doThreshold\"] = True`\n",
    "3. Set the level to threshold or binarize at with `env[\"threshold\"]`.\n",
    "4. Set the threshold/binarization direction with `env[\"direction\"]`.\n",
    "\n",
    "    - If direction is `twosided`, will **threshold/binarize outside** the threshold level.\n",
    "        - Example: if threshold is 1 and direction is \"twosided\", then values **between** -1 and +1 will be zeroed.\n",
    "\n",
    "\n",
    "    - If direction is `less`, will **zero out values greater than** the threshold level.\n",
    "        - Example: if threshold is -1 and direction is \"less\", then values **greater** than -1 will be zeroed.\n",
    "\n",
    "\n",
    "    - If direction is `greater`, will **zero out values less than the** threshold level.\n",
    "        - Example: if threshold is +1 and direction is \"greater\", then values **less** than +1 will be zeroed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Options\n",
    "\n",
    "# The Default settings do no thresholding and no binarization.\n",
    "\n",
    "# If True, applies a threshold to the image. If you want no thresholding, set to False.\n",
    "env[\"doThreshold\"] = False\n",
    "\n",
    "# If True, binarizes ROIs at some threshold. If you want weighted ROIs, set to False.\n",
    "# If binarize is set to True, doThreshold must also be True.\n",
    "env[\"binarize\"] = False\n",
    "\n",
    "# Binarize or threshold weighted image at this value.\n",
    "env[\"threshold\"] = 0\n",
    "\n",
    "# Set threshold/binarize direction\n",
    "env[\"direction\"] = \"twosided\"\n",
    "\n",
    "# Type of Registration Fusion approaches used to generate the mappings (\"RF_M3Z\" or \"RF_ANTs\"). Defaults to \"RF_ANTs\"\n",
    "# RF-M3Z is recommended if data was registered from subject's space to the volumetric atlas space using FreeSurfer.\n",
    "# RF-ANTs is recommended if such registrations were carried out using other tools, especially ANTs.\n",
    "env[\"RF_type\"] = \"RF_ANTs\"\n",
    "\n",
    "# Interpolation method for conversion from surface to volume.\n",
    "env[\"interp\"] = \"linear\"\n",
    "\n",
    "env[\"meta_df\"] = preprocessing.reslice_and_convert_rois(\n",
    "    env[\"lesion_type\"],\n",
    "    env[\"meta_df\"],\n",
    "    env[\"vol_spaces\"],\n",
    "    env[\"surf_spaces\"],\n",
    "    env[\"project_path\"],\n",
    "    env[\"doThreshold\"],\n",
    "    env[\"binarize\"],\n",
    "    env[\"threshold\"],\n",
    "    env[\"direction\"],\n",
    "    env[\"RF_type\"],\n",
    "    env[\"interp\"],\n",
    "    use_datalad,\n",
    ")\n",
    "preprocessing.save_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 2. Review the lesions to see if any extend outside of the brain, are blank, and/or look weird:\n",
    "\n",
    "`If visualize = True` The code will show you each lesion, marked with where it is extending outside of the brain mask\n",
    "\n",
    "NOTE: While we use the `MNI152_T1_2mm_brain_mask_dil` mask for the connectivity,<br>\n",
    "I believe it makes sense to still use the more restrictive `MNI152_T1_2mm_brain_mask` here to mask the lesions, since this better excludes ventricles and sinuses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set visualize to True to see pictures of each lesion, and False if you've already done this and just want to skip ahead\n",
    "# Note: This will only visualize volume lesions. Surface atrophy will not be visualized if visualise is True\n",
    "\n",
    "env[\"visualize\"] = False\n",
    "\n",
    "env[\"meta_df\"], env[\"brain_masks\"] = preprocessing.review_lesions(\n",
    "    env[\"visualize\"],\n",
    "    env[\"lesion_type\"],\n",
    "    env[\"meta_df\"],\n",
    "    env[\"project_path\"],\n",
    "    env[\"vol_spaces\"],\n",
    "    env[\"surf_spaces\"],\n",
    "    env[\"brain_mask_2mm\"],\n",
    "    env[\"brain_mask_1mm\"],\n",
    "    env[\"brain_mask_fs5\"],\n",
    "    use_datalad,\n",
    ")\n",
    "preprocessing.save_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 3. Trim the lesions to remove voxels outside the brain mask:\n",
    "\n",
    "NOTE: This only affects the files in `Project/Lesions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env[\"meta_df\"] = preprocessing.trim_lesions(\n",
    "    env[\"meta_df\"],\n",
    "    env[\"vol_spaces\"],\n",
    "    env[\"surf_spaces\"],\n",
    "    env[\"project_path\"],\n",
    "    env[\"brain_masks\"],\n",
    "    use_datalad,\n",
    ")\n",
    "preprocessing.save_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4. Before we generate the fcMaps, show me an overview of where these lesions are located:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.show_lesion_overview(\n",
    "    env[\"meta_df\"],\n",
    "    env[\"vol_spaces\"],\n",
    "    env[\"surf_spaces\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 5. Generate JSON sidecars for lesion niftis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.generate_roi_json_sidecars(\n",
    "    env[\"meta_df\"],\n",
    "    env[\"vol_spaces\"],\n",
    "    env[\"surf_spaces\"],\n",
    "    env[\"project_path\"],\n",
    "    env[\"lesion_type\"],\n",
    "    use_datalad,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Generate Functional/Structural Connectivity Maps:\n",
    "\n",
    "This calls the parallel connectome_quick/BCB Disconnectome/LQT function with your cleaned seeds and the connectome you specified above.<br>\n",
    "This will take a few minutes to a few hours depending on the number of seeds and the size of the connectome, e.g., 100 vs 1000 subjects.\n",
    "\n",
    "If you get errors regarding mismatching number of voxels begin your seeds and the connectome you have chosen, you may need to specify a brain mask:\n",
    "- `222` has 285903 voxels (this was used in the past)\n",
    "- `mni_icbm152` has 225222 voxels\n",
    "- `MNI152_T1_2mm_brain_mask` has 228483 voxels\n",
    "- `MNI152_T1_2mm_brain_mask_dil1` has 262245 voxels\n",
    "- `MNI152_T1_2mm_brain_mask_dil` has 292019 voxels (current default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, save list of cleaned lesions to file:\n",
    "env[\"set_connectivity_analyses\"] = preprocessing.generate_cleaned_roi_lists(\n",
    "    env[\"set_connectivity_analyses\"],\n",
    "    env[\"meta_df\"],\n",
    "    env[\"project_path\"])\n",
    "preprocessing.save_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit jobs to cluster\n",
    "for analysis in env[\"set_connectivity_analyses\"]:\n",
    "    if(analysis['tool'] == \"connectome_quick\"):\n",
    "        sf.call_connectome_quick(\n",
    "            read_input=os.path.abspath(analysis['input_list']),\n",
    "            output_directory=os.path.abspath((os.path.join(env[\"project_path\"],\"fc_temp\"))),\n",
    "            numWorkers=4,\n",
    "            command=\"seed\",\n",
    "            connectome=analysis['roi_connectome'],\n",
    "            brain_connectome=analysis['connectome'],\n",
    "            brain_space=\"\",\n",
    "            output_mask=\"\",\n",
    "            cluster_name=\"eristwo-slurm\",\n",
    "            username=env[\"cluster_user\"],\n",
    "            cluster_email=env[\"creator_email\"],\n",
    "            dryrun=False,\n",
    "            queue = \"normal,nimlab\",\n",
    "            cores = \"4\",\n",
    "            memory = \"16000\",\n",
    "            no_warn=\"False\",\n",
    "            job_name=\"\",\n",
    "            job_time=\"\",\n",
    "            num_nodes=\"\",\n",
    "            num_tasks=\"\",\n",
    "            x11_forwarding=\"\",\n",
    "            service_class=\"\",\n",
    "            debug=False,\n",
    "            extra=\"\"\n",
    "        )\n",
    "    elif(analysis['tool'] == \"BCB Disconnectome\"):\n",
    "        sf.call_disconnectome(\n",
    "            input_directory = os.path.abspath(analysis['input_list']),\n",
    "            output_directory = os.path.abspath((os.path.join(env[\"project_path\"],\"fc_temp\"))),\n",
    "            connectome_directory = analysis['connectome'],\n",
    "            threshold = 0,\n",
    "            cluster_name=\"eristwo-slurm\",\n",
    "            username=env[\"cluster_user\"],\n",
    "            cluster_email=env[\"creator_email\"],\n",
    "            queue = \"normal,nimlab\",\n",
    "            cores = \"4\",\n",
    "            memory = \"8000\",\n",
    "            dryrun=False,\n",
    "            job_name=\"\",\n",
    "            job_time=\"\",\n",
    "            num_nodes=\"\",\n",
    "            num_tasks=\"\",\n",
    "            x11_forwarding=\"\",\n",
    "            service_class=\"\",\n",
    "            debug=False,\n",
    "            extra=\"\"\n",
    "        )\n",
    "    elif(analysis['tool'] == \"Lesion Quantification Toolkit\"):\n",
    "        sf.call_lesion_quantification_toolkit(\n",
    "            input_directory = os.path.abspath(analysis['input_list']),\n",
    "            output_directory = os.path.abspath((os.path.join(env[\"project_path\"],\"fc_temp\"))),\n",
    "            dataset_name = \"preprocessing\",\n",
    "            connectivity_type = env[\"lqt_options\"][\"connectivity_type\"],\n",
    "            sspl_spared_thresh = env[\"lqt_options\"][\"sspl_spared_thresh\"],\n",
    "            smooth = env[\"lqt_options\"][\"smooth\"],\n",
    "            cluster_name=\"eristwo-slurm\",\n",
    "            username=env[\"cluster_user\"],\n",
    "            cluster_email=env[\"creator_email\"],\n",
    "            queue = \"normal,nimlab\",\n",
    "            cores = \"2\",\n",
    "            memory = \"4000\",\n",
    "            dryrun=False,\n",
    "            job_name=\"\",\n",
    "            job_time=\"\",\n",
    "            num_nodes=\"\",\n",
    "            num_tasks=\"\",\n",
    "            x11_forwarding=\"\",\n",
    "            service_class=\"\",\n",
    "            debug=False,\n",
    "            extra=\"\"\n",
    "        )\n",
    "preprocessing.save_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize Functional/Structural Connectivity Output\n",
    "**DO NOT RUN THIS CELL MORE THAN ONCE!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env[\"meta_df\"] = preprocessing.organize_connectivity_output(\n",
    "    env[\"meta_df\"],\n",
    "    env[\"set_connectivity_analyses\"],\n",
    "    env[\"lesion_type\"],\n",
    "    env[\"project_path\"],\n",
    "    env[\"lqt_options\"]\n",
    "    )\n",
    "\n",
    "preprocessing.save_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Steps to allow you to easily use the results of your hard work:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Make a Human-readable `./README.md` that notes the original location of the seeds and which connectome was used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.generate_readme(\n",
    "    env[\"meta_df\"],\n",
    "    env[\"set_connectivity_analyses\"],\n",
    "    env[\"project_path\"],\n",
    "    env[\"project_name\"],\n",
    "    env[\"creator_email\"],\n",
    "    env[\"input_folder\"],\n",
    "    env[\"lesions\"],\n",
    "    env[\"lesion_type\"]\n",
    "    )\n",
    "\n",
    "preprocessing.save_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Clone dataset to dl_archive and update the database\n",
    "\n",
    "**NOTE:** Sometimes this cell will fail the first time you run it. If you get a warning try running a second time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preprocessing.upload_to_dl_archive(\n",
    "    env[\"project_path\"],\n",
    "    env[\"project_name\"],\n",
    "    env[\"vol_spaces\"],\n",
    "    env[\"surf_spaces\"],\n",
    "    env[\"lesion_type\"]\n",
    ")\n",
    "preprocessing.save_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your project metadata is now acccessible via the metadata_editor notebook. You can build a csv file via the \"Browse\" tab. Please remember to add some helpful tags to it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3.10 Nimlab",
   "language": "python",
   "name": "nimlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
