{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import platform\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Niftis from a CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "def csv_of_nifti_filepaths_to_dataframe(csv_path: str) -> pd.DataFrame:\n",
    "    '''\n",
    "    Reads a CSV file containing paths to nifti files, imports the nifti files, flattens them,\n",
    "    removes NaNs, and creates a dataframe in the specified format.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    csv_path : str\n",
    "        Path to the CSV file containing paths to nifti files.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        A dataframe where columns represent flattened nifti files and rows represent voxels.\n",
    "        All values are zero, except for lesions which are binarized at 1.\n",
    "    \n",
    "    '''\n",
    "    # Read the CSV file\n",
    "    file_paths = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Initialize an empty list to store flattened nifti data\n",
    "    nifti_data = []\n",
    "    \n",
    "    # Iterate through the file paths and import nifti files\n",
    "    for index, row in file_paths.iterrows():\n",
    "        nifti_file_path = row[0]\n",
    "        \n",
    "        # Load the nifti file\n",
    "        nifti_image = nib.load(nifti_file_path)\n",
    "        \n",
    "        # Get the data as a numpy array\n",
    "        nifti_array = nifti_image.get_fdata()\n",
    "        \n",
    "        # Flatten the numpy array\n",
    "        flattened_array = nifti_array.flatten()\n",
    "        \n",
    "        # Replace NaNs with zeros\n",
    "        flattened_array[np.isnan(flattened_array)] = 0\n",
    "        \n",
    "        # Binarize the flattened array\n",
    "        flattened_array = np.where(flattened_array > 0, 1, 0)\n",
    "        \n",
    "        # Append the flattened array to the list\n",
    "        nifti_data.append(flattened_array)\n",
    "    \n",
    "    # Create a dataframe from the list of flattened arrays\n",
    "    df = pd.DataFrame(np.column_stack(nifti_data))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Niftis from a Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will search:  /Users/cu135/Dropbox (Partners HealthCare)/studies/atrophy_seeds_2023/shared_analysis/niftis_for_elmira/vbm_derivatives/mri/mwp20002.nii\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mwp20002.nii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749348</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749349</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749350</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749351</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749352</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1749353 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mwp20002.nii\n",
       "0                 0.0\n",
       "1                 0.0\n",
       "2                 0.0\n",
       "3                 0.0\n",
       "4                 0.0\n",
       "...               ...\n",
       "1749348           0.0\n",
       "1749349           0.0\n",
       "1749350           0.0\n",
       "1749351           0.0\n",
       "1749352           0.0\n",
       "\n",
       "[1749353 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from calvin_utils.file_utils.import_matrices import import_matrices_from_folder\n",
    "#set file path to'' if you have specified the full path to the nifti file itself\n",
    "path_1 = '/Users/cu135/Dropbox (Partners HealthCare)/studies/atrophy_seeds_2023/shared_analysis/niftis_for_elmira/vbm_derivatives/mri'\n",
    "df_1 = import_matrices_from_folder(path_1, file_pattern='mwp20002.nii')\n",
    "# /Users/cu135/Dropbox (Partners HealthCare)/memory/functional_networks/ferguson_2019_networks/control_lesions/auditory_hallucination_lesions/sub-08uNodau1/roi/sub-08uNodau1_lesionMask.nii.gz\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will search:  /Users/cu135/Dropbox (Partners HealthCare)/studies/atrophy_seeds_2023/shared_analysis/niftis_for_elmira/vbm_derivatives/mri/mwp30002.nii\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mwp30002.nii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749348</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749349</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749350</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749351</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749352</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1749353 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mwp30002.nii\n",
       "0                 0.0\n",
       "1                 0.0\n",
       "2                 0.0\n",
       "3                 0.0\n",
       "4                 0.0\n",
       "...               ...\n",
       "1749348           0.0\n",
       "1749349           0.0\n",
       "1749350           0.0\n",
       "1749351           0.0\n",
       "1749352           0.0\n",
       "\n",
       "[1749353 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_2 = '/Users/cu135/Dropbox (Partners HealthCare)/studies/atrophy_seeds_2023/shared_analysis/niftis_for_elmira/vbm_derivatives/mri'\n",
    "df_2 = import_matrices_from_folder(path_2, file_pattern='mwp30002.nii')\n",
    "df_2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsample a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from nilearn import image as nli\n",
    "from nilearn.image import resample_to_img\n",
    "import nibabel as nib\n",
    "import nibabel.processing\n",
    "from tqdm import tqdm\n",
    "from nimlab import datasets as nimds\n",
    "\n",
    "\n",
    "def downsample_image(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Function to downsample a 3D image to a new voxel size using a target affine.\n",
    "    \n",
    "    Args:\n",
    "    input_path (str): Filepath to the input image.\n",
    "    output_path (str): Filepath to save the output image.\n",
    "    target_voxel_size (list): Target voxels to resample to.\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    img = nib.load(input_path)\n",
    "    mni_mask = nimds.get_img(\"mni_icbm152\")\n",
    "    \n",
    "    # Downsample the image using the target affine\n",
    "    resampled_img = resample_to_img(img, mni_mask)\n",
    "\n",
    "    # Save the downsampled image\n",
    "    nib.save(resampled_img, output_path)\n",
    "    \n",
    "mni_mask = nimds.get_img(\"mni_icbm152\")\n",
    "mask_data = mni_mask.get_fdata().flatten()\n",
    "\n",
    "def downsample_to_mni152_images_in_folder(input_folder_pattern):\n",
    "    \"\"\"\n",
    "    Function to downsample all 3D images in a folder to a new voxel size.\n",
    "    \n",
    "    Args:\n",
    "    input_folder_pattern (str): Glob pattern to find the input images.\n",
    "    target_voxel_size (list): Target voxels to resample to.\n",
    "    \"\"\"\n",
    "    # Find all input image filepaths\n",
    "    input_filepaths = glob.glob(input_folder_pattern)\n",
    "    print('Will search:, ', input_folder_pattern)\n",
    "\n",
    "    # Loop over each input image\n",
    "    for input_path in tqdm(input_filepaths):\n",
    "        # Define the output path\n",
    "        base, ext = os.path.splitext(input_path)\n",
    "        if ext == '.gz':\n",
    "            base, ext2 = os.path.splitext(base)\n",
    "            ext = ext2 + ext\n",
    "        output_path = base + '_resampled' + ext\n",
    "\n",
    "        # Downsample the image\n",
    "        downsample_image(input_path, output_path)\n",
    "    print('Drownsampled images saved to: ' + output_path)\n",
    "\n",
    "\n",
    "# Usage:\n",
    "# downsample_images_in_folder('/path/to/your/images/*/*/anat/*mwp1*.nii', '/path/to/target/resolution/image.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_to_check = '/Users/cu135/Dropbox (Partners HealthCare)/resources/atlases/MNI_structures/cortex'\n",
    "file_pattern = '*'\n",
    "#----------------------------------------------------------------DO NOT TOUCH\n",
    "downsample_to_mni152_images_in_folder(os.path.join(directory_to_check, file_pattern))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nimlab import datasets as nimds\n",
    "mni_mask = nimds.get_img(\"mni_icbm152\")\n",
    "mask_data = mni_mask.get_fdata().flatten()\n",
    "brain_indices = np.where(mask_data > 0)[0]\n",
    "df_1 = df_1.iloc[brain_indices, :]\n",
    "# df_2 = df_2.iloc[brain_indices, :]\n",
    "\n",
    "# print('Dataframes have been masked such that their shapes are: ', df_1.shape, df_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resample a High Resolution Nifti to Another Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "def reslice_roi_with_flirt(roi_path, template_path, output_path=None):\n",
    "    \"\"\"\n",
    "    Reslice an ROI NIfTI image to match the resolution and space of a whole-brain template\n",
    "    using FSL's FLIRT, maintaining its correct spatial location.\n",
    "\n",
    "    Parameters:\n",
    "    - roi_path (str): Path to the ROI NIfTI image.\n",
    "    - template_path (str): Path to the whole-brain template NIfTI image.\n",
    "    - output_path (str, optional): Path for the output resliced NIfTI image. If not provided,\n",
    "      the output will be saved in the same directory as `roi_path` with '_resliced' appended to the filename.\n",
    "\n",
    "    Returns:\n",
    "    - str: Path to the resliced image if successful, None otherwise.\n",
    "    \"\"\"\n",
    "    if output_path is None:\n",
    "        # Generate output path by appending '_resliced' to the ROI filename\n",
    "        roi_dir, roi_filename = os.path.split(roi_path)\n",
    "        roi_basename, roi_ext = os.path.splitext(roi_filename)\n",
    "        if roi_ext == '.gz':\n",
    "            roi_basename, _ = os.path.splitext(roi_basename)\n",
    "            roi_ext = '.nii.gz'\n",
    "        output_path = os.path.join(roi_dir, f\"{roi_basename}_resliced{roi_ext}\")\n",
    "\n",
    "    # Construct the FLIRT command for reslicing\n",
    "    flirt_command = [\n",
    "        'flirt',\n",
    "        '-in', roi_path,\n",
    "        '-ref', template_path,\n",
    "        '-out', output_path,\n",
    "        '-applyxfm', '-usesqform',\n",
    "        '-init', '/usr/local/fsl/etc/flirtsch/ident.mat'\n",
    "    ]\n",
    "\n",
    "    # Execute the FLIRT command\n",
    "    result = subprocess.run(flirt_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "    # Check for errors in the FLIRT command execution\n",
    "    if result.returncode != 0:\n",
    "        print(f\"Error reslicing ROI with FLIRT: {result.stderr.decode('utf-8')}\")\n",
    "        return None\n",
    "\n",
    "    return output_path\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_to_resample_path = '/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/MATLAB/leaddbs/templates/space/MNI152NLin2009bAsym/atlases/DISTAL Nano (Ewert 2017)/rh/STN.nii.gz'\n",
    "reference_image_path = '/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Work/Software/Research/nimlab/nimlab/data/MNI152_T1_2mm_brain_mask.nii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/MATLAB/leaddbs/templates/space/MNI152NLin2009bAsym/atlases/DISTAL Nano (Ewert 2017)/rh/STN_resliced.nii.gz'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reslice_roi_with_flirt(roi_path=image_to_resample_path, template_path=reference_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask Nifti By Another with FSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "def mask_nifti(mask_path, image_path):\n",
    "    # Extract directory and filename without extension\n",
    "    image_dir, image_filename = os.path.split(image_path)\n",
    "    image_basename, image_ext = os.path.splitext(image_filename)\n",
    "    \n",
    "    # Ensure the extension is .nii or .nii.gz\n",
    "    if image_ext == '.gz':\n",
    "        image_basename, _ = os.path.splitext(image_basename)\n",
    "        image_ext = '.nii.gz'\n",
    "    \n",
    "    # Define the output path\n",
    "    output_path = os.path.join(image_dir, f\"{image_basename}_masked{image_ext}\")\n",
    "    \n",
    "    # Build the FSL command\n",
    "    fsl_command = ['fslmaths', image_path, '-mas', mask_path, output_path]\n",
    "    \n",
    "    # Execute the command\n",
    "    result = subprocess.run(fsl_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    \n",
    "    # Check if the command executed successfully\n",
    "    if result.returncode != 0:\n",
    "        # An error occurred, handle it here\n",
    "        print(f\"Error running fslmaths: {result.stderr.decode('utf-8')}\")\n",
    "        return None\n",
    "    \n",
    "    # Return the path to the masked image\n",
    "    return output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_path = '/Users/cu135/hires_backdrops/STN_mni152.nii'\n",
    "image_path = '/Users/cu135/Dropbox (Partners HealthCare)/resources/published_networks/niftis/Memory Network T Conn.nii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked image saved to: /Users/cu135/Dropbox (Partners HealthCare)/resources/published_networks/niftis/Memory Network T Conn_masked.nii\n"
     ]
    }
   ],
   "source": [
    "masked_image_path = mask_nifti(mask_path=mask_path, image_path=image_path)\n",
    "print(f\"Masked image saved to: {masked_image_path}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.matrix_utilities import threshold_matrix \n",
    "threshold_1 = 2\n",
    "threshold_2 = -2\n",
    "#This will make everything NOT meeting the condition 0 \n",
    "df_1 = df_1.where(df_1 < threshold_2, 0)\n",
    "# df_2.where(df_2 < threshold_2, 0)\n",
    "df_1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulate Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Coordinates to Index\n",
    "from calvin_utils.matrix_utilities import convert_coordinate_to_index\n",
    "from nimlab import datasets as nimds\n",
    "#Mask within the brain\n",
    "mni_mask = nimds.get_img(\"mni_icbm152\")\n",
    "mask_affine = mni_mask.affine\n",
    "\n",
    "coordinate_tuple = (-2,30,56)\n",
    "index = convert_coordinate_to_index(coordinate_tuple, mask_affine)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Index to Coordinates\n",
    "from calvin_utils.matrix_utilities import convert_index_to_coordinate\n",
    "from nimlab import datasets as nimds\n",
    "#Mask within the brain\n",
    "mni_mask = nimds.get_img(\"mni_icbm152\")\n",
    "mask_affine = mni_mask.affine\n",
    "\n",
    "index_tuple = (46, 78, 64)\n",
    "index = convert_index_to_coordinate(index_tuple, mask_affine)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Index (Voxel Coordinates) To Flat Array Index (1 dimensional array after running ___.flatten())\n",
    "from calvin_utils.matrix_utilities import index_in_flattened_nifti\n",
    "from nimlab import datasets as nimds\n",
    "#Mask within the brain\n",
    "mni_mask = nimds.get_img(\"mni_icbm152\")\n",
    "mask_shape = mni_mask.shape\n",
    "\n",
    "index_tuple = (46, 78, 64)\n",
    "index = index_in_flattened_nifti(index_tuple, mask_shape)\n",
    "index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run FSL Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.run_fsl_cluster import run_fsl_cluster\n",
    "run_fsl_cluster(path_1, outdir=out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Percentage of Nifti Within a Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from nimlab import datasets as nimds\n",
    "\n",
    "def calculate_ratio(non_binary_image, binary_mask):\n",
    "    \"\"\"\n",
    "    Calculate the ratio of nonzero values in the non-binary image that coincide with\n",
    "    the 1s in the binary mask, to the total number of nonzero values in the non-binary image.\n",
    "    \n",
    "    Parameters:\n",
    "    - non_binary_image: NumPy array representing the non-binary image\n",
    "    - binary_mask: NumPy array representing the binary mask\n",
    "    \n",
    "    Returns:\n",
    "    - ratio: The calculated ratio\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure that both images have the same shape\n",
    "    if non_binary_image.shape != binary_mask.shape:\n",
    "        raise ValueError(\"The shapes of the non-binary image and the binary mask must be the same.\")\n",
    "    \n",
    "    # Multiply the non-binary image by the binary mask\n",
    "    masked_image = non_binary_image * binary_mask\n",
    "    \n",
    "    # Count the number of nonzero values in the masked image\n",
    "    count_masked_nonzero = np.count_nonzero(masked_image)\n",
    "    \n",
    "    # Count the number of nonzero values in the non-binary image\n",
    "    count_non_binary_nonzero = np.count_nonzero(non_binary_image)\n",
    "    \n",
    "    # Calculate the ratio\n",
    "    if count_non_binary_nonzero == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        ratio = count_masked_nonzero / count_non_binary_nonzero\n",
    "    \n",
    "    return ratio\n",
    "\n",
    "class PermutationTest:\n",
    "    def __init__(self, non_binary_image, binary_mask, mni_mask, n_permutations=1000):\n",
    "        self.non_binary_image = non_binary_image.get_fdata()\n",
    "        self.binary_mask = binary_mask.get_fdata()\n",
    "        self.mni_mask = mni_mask.get_fdata()\n",
    "        self.n_permutations = n_permutations\n",
    "        self.permuted_ratios = []\n",
    "        self.observed_ratio = calculate_ratio(self.non_binary_image, self.binary_mask)\n",
    "    \n",
    "    def permute_and_calculate(self):\n",
    "        for _ in tqdm(range(self.n_permutations)):\n",
    "            # Find the indices where the MNI mask is non-zero\n",
    "            mni_indices = np.where(self.mni_mask > 0)\n",
    "            \n",
    "            # Extract the corresponding values from the binary mask\n",
    "            values_to_permute = self.non_binary_image[mni_indices]\n",
    "            \n",
    "            # Shuffle only these values\n",
    "            np.random.shuffle(values_to_permute)\n",
    "            \n",
    "            # Create a new mask with the shuffled values placed back into their original positions\n",
    "            shuffled_mask = np.zeros_like(self.binary_mask)\n",
    "            shuffled_mask[mni_indices] = values_to_permute\n",
    "            \n",
    "            # Calculate the ratio using the shuffled mask and add it to the list\n",
    "            permuted_ratio = calculate_ratio(self.non_binary_image, shuffled_mask)\n",
    "            self.permuted_ratios.append(permuted_ratio)\n",
    "    \n",
    "    def calculate_p_value(self):\n",
    "        self.permuted_ratios = np.array(self.permuted_ratios)\n",
    "        p_value = np.mean(self.permuted_ratios >= self.observed_ratio)\n",
    "        return p_value\n",
    "    \n",
    "    def return_percent_overlap(self):\n",
    "        return self.observed_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run to evaluate the singular percent overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "# Load the NIfTI files\n",
    "non_binary_img = nib.load('/Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/BIDS_PD_DBS_STN_WURZBURG/response_topology/voxelwise_glm/stim_by_age/corrected_p_vals/nilean_corrected_fpr_p_values.nii.gz')\n",
    "binary_mask_img = nib.load('/Users/cu135/Dropbox (Partners HealthCare)/resources/published_networks/memory_network_thresholded/above_t7_below_tneg7.nii')\n",
    "permutation_tester = PermutationTest(non_binary_img, binary_mask_img, nimds.get_img(\"mni_icbm152\"), n_permutations=10000)\n",
    "\n",
    "# Perform permutations and calculate ratios\n",
    "permutation_tester.permute_and_calculate()\n",
    "p_value = permutation_tester.calculate_p_value()\n",
    "percent_overlap = permutation_tester.return_percent_overlap()\n",
    "# Calculate the p-valuea\n",
    "print(f'{percent_overlap} percent overlap (p={p_value})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run to evaluate the "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Dice Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def dice_coefficient(df1: pd.DataFrame, df2: pd.DataFrame) -> float:\n",
    "    '''\n",
    "    Calculates the Dice Coefficient between two dataframes containing binary lesion masks.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df1 : pd.DataFrame\n",
    "        The first dataframe, where columns represent flattened nifti files and rows represent voxels.\n",
    "        All values are zero, except for lesions which are binarized at 1.\n",
    "        \n",
    "    df2 : pd.DataFrame\n",
    "        The second dataframe, where columns represent flattened nifti files and rows represent voxels.\n",
    "        All values are zero, except for lesions which are binarized at 1.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        The Dice Coefficient, a value between 0 and 1, where 1 represents a perfect overlap.\n",
    "        \n",
    "    '''\n",
    "    # Check if in numpy array, and convert the dataframes to numpy arrays if required\n",
    "    if isinstance(df1, np.ndarray):\n",
    "        array1 = df1\n",
    "    else:\n",
    "        array1 = df1.to_numpy()\n",
    "    if isinstance(df2, np.ndarray):\n",
    "        array2 = df2\n",
    "    else:\n",
    "        array2 = df2.to_numpy()\n",
    "    \n",
    "    # Calculate the intersection of non-zero elements\n",
    "    intersection = np.sum(np.logical_and(array1, array2))\n",
    "    \n",
    "    # Calculate the number of non-zero elements in each array\n",
    "    num_elements_array1 = np.sum(np.count_nonzero(array1))\n",
    "    num_elements_array2 = np.sum(np.count_nonzero(array2))\n",
    "    \n",
    "    # Calculate the Dice Coefficient\n",
    "    dice_coefficient = (2 * intersection) / (num_elements_array1 + num_elements_array2)\n",
    "    \n",
    "    return dice_coefficient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will search:  /Users/cu135/Dropbox (Partners HealthCare)/studies/atrophy_seeds_2023/shared_analysis/niftis_for_elmira/vbm_derivatives/mri/mwp10002.nii\n",
      "I will search:  /Users/cu135/Dropbox (Partners HealthCare)/studies/atrophy_seeds_2023/shared_analysis/niftis_for_elmira/vbm_derivatives/mri/mwp20002.nii\n",
      "I will search:  /Users/cu135/Dropbox (Partners HealthCare)/studies/atrophy_seeds_2023/shared_analysis/niftis_for_elmira/vbm_derivatives/mri/mwp30002.nii\n",
      "I will search:  /Users/cu135/Dropbox (Partners HealthCare)/studies/atrophy_seeds_2023/shared_analysis/niftis_for_elmira/vbm_derivatives/mri/wm0002.nii\n"
     ]
    }
   ],
   "source": [
    "from calvin_utils.file_utils.import_matrices import import_matrices_from_folder\n",
    "#set file path to'' if you have specified the full path to the nifti file itself\n",
    "path_1 = '/Users/cu135/Dropbox (Partners HealthCare)/studies/atrophy_seeds_2023/shared_analysis/niftis_for_elmira/vbm_derivatives/mri'\n",
    "GM = import_matrices_from_folder(path_1, file_pattern='mwp10002.nii')\n",
    "# /Users/cu135/Dropbox (Partners HealthCare)/memory/functional_networks/ferguson_2019_networks/control_lesions/auditory_hallucination_lesions/sub-08uNodau1/roi/sub-08uNodau1_lesionMask.nii.gz\n",
    "WM = import_matrices_from_folder(path_1, file_pattern='mwp20002.nii')\n",
    "CSF = import_matrices_from_folder(path_1, file_pattern='mwp30002.nii')\n",
    "BRAIN = import_matrices_from_folder(path_1, file_pattern='wm0002.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GM-brain: 0.7526834141831452\n",
      "WM-brain: 0.6080165467944493\n",
      "CSF-brain: 0.26480460520131166\n"
     ]
    }
   ],
   "source": [
    "from calvin_utils.nifti_utils.matrix_utilities import threshold_matrix\n",
    "from calvin_utils.statistical_utils.fisher_z_transform import fisher_z_transform\n",
    "from nimlab import datasets as nimds\n",
    "\n",
    "GM = np.where(GM > 0.2 , 1, 0)\n",
    "WM = np.where(WM > 0.2, 1, 0)\n",
    "CSF = np.where(CSF > 0.2 , 1, 0)\n",
    "BRAIN = np.where(BRAIN > 0.4 , 1, 0)\n",
    "\n",
    "print(\"GM-brain:\", dice_coefficient(GM, BRAIN))\n",
    "print(\"WM-brain:\", dice_coefficient(WM, BRAIN))\n",
    "print(\"CSF-brain:\", dice_coefficient(CSF, BRAIN))\n",
    "\n",
    "\n",
    "#Make sure you specify what column you want. \n",
    "# observed_dice_coefficient = dice_coefficient(mx_1, mx_2)\n",
    "# print('Dice coefficient:', observed_dice_coefficient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'thresholded_df_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m voxel_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(n_permutations)):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Permute dataframes\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     permuted_df_1 \u001b[38;5;241m=\u001b[39m brain_permutation(\u001b[43mthresholded_df_1\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\u001b[38;5;241m.\u001b[39mto_numpy()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), looped_permutation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m     permuted_df_2 \u001b[38;5;241m=\u001b[39m brain_permutation(thresholded_df_2\u001b[38;5;241m.\u001b[39mcopy()\u001b[38;5;241m.\u001b[39mto_numpy()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), looped_permutation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Threshold and calculate the Dice coefficient for the permuted dataframes\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'thresholded_df_1' is not defined"
     ]
    }
   ],
   "source": [
    "# Permute the Dice Coefficient\n",
    "from calvin_utils.permutation_analysis_utils.permutation_utils.palm import brain_permutation\n",
    "from tqdm import tqdm \n",
    "\n",
    "# Assuming df_1 and df_2 are your original dataframes\n",
    "n_permutations = 1000\n",
    "dice_coefficients = []\n",
    "voxel_index = 0\n",
    "for i in tqdm(range(n_permutations)):\n",
    "    # Permute dataframes\n",
    "    permuted_df_1 = brain_permutation(thresholded_df_1.copy().to_numpy().reshape(1,-1), looped_permutation=True)\n",
    "    permuted_df_2 = brain_permutation(thresholded_df_2.copy().to_numpy().reshape(1,-1), looped_permutation=True)\n",
    "\n",
    "    # Threshold and calculate the Dice coefficient for the permuted dataframes\n",
    "    permuted_dice_coefficient = dice_coefficient(permuted_df_1, permuted_df_2)\n",
    "\n",
    "    # Store the Dice coefficient\n",
    "    dice_coefficients.append(permuted_dice_coefficient)\n",
    "\n",
    "# Convert the list to a numpy array\n",
    "dice_coefficients = np.array(dice_coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same, but with multiprocessing\n",
    "import concurrent.futures\n",
    "from calvin_utils.matrix_utilities import dice_coefficient\n",
    "\n",
    "n_permutations = 1000\n",
    "dice_coefficients = []\n",
    "voxel_index = 0\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=8) as executor:\n",
    "    #Begin submitting the masked data to the permutor\n",
    "    results = []\n",
    "    for i in tqdm(range(n_permutations), desc=\"Jobs Launched\"):\n",
    "        permuted_df_1 = brain_permutation(thresholded_df_1.copy().to_numpy().reshape(1,-1), looped_permutation=True)\n",
    "        permuted_df_2 = brain_permutation(thresholded_df_2.copy().to_numpy().reshape(1,-1), looped_permutation=True)\n",
    "        \n",
    "        result = executor.submit(dice_coefficient, permuted_df_1, permuted_df_2)\n",
    "        results.append(result)\n",
    "        \n",
    "    progress_bar = tqdm(total=n_permutations, desc=\"Jobs Finalized\")\n",
    "    for result in concurrent.futures.as_completed(results):\n",
    "        \n",
    "        #Input the permuted data into the array\n",
    "        permuted_dice_coefficient = result.result()\n",
    "        dice_coefficients.append(permuted_dice_coefficient)\n",
    "        \n",
    "        #Update visualization\n",
    "        progress_bar.update()\n",
    "    progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('empiric p: ', np.count_nonzero(dice_coefficients>observed_dice_coefficient))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of Lesion Incidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    return (df - df.min()) / (df.max() - df.min())\n",
    "\n",
    "summed_voxels = df_1.sum(axis=1)\n",
    "summed_voxels2 = df_2.sum(axis=1)\n",
    "\n",
    "summed_voxels_df = pd.DataFrame({'Voxel_Index': summed_voxels.index, 'Summed_Voxel_Value': summed_voxels.values})\n",
    "summed_voxels_df2 = pd.DataFrame({'Voxel_Index': summed_voxels.index, 'Summed_Voxel_Value': summed_voxels2.values})\n",
    "\n",
    "\n",
    "summed_voxels_df['Normalized_Summed_Voxel_Value'] = normalize(summed_voxels_df['Summed_Voxel_Value'])\n",
    "summed_voxels_df2['Normalized_Summed_Voxel_Value'] = normalize(summed_voxels_df2['Summed_Voxel_Value'])\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the first DataFrame with normalized values\n",
    "plt.plot(summed_voxels_df['Voxel_Index'], summed_voxels_df['Normalized_Summed_Voxel_Value'], label='Dataset 1')\n",
    "\n",
    "# Plot the second DataFrame with normalized values\n",
    "plt.plot(summed_voxels_df2['Voxel_Index'], summed_voxels_df2['Normalized_Summed_Voxel_Value'], label='Dataset 2')\n",
    "\n",
    "plt.xlabel('Voxel Index')\n",
    "plt.ylabel('Normalized Summed Voxel Value')\n",
    "plt.title('Normalized Summed Voxel Values vs. Voxel Index')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a Heatmap from a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_1, index_col=False)\n",
    "display(df)\n",
    "#Create heatmap of correlation matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(15, 13))\n",
    "sns.heatmap(df, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "#Save the Elbow Plot Above\n",
    "save_dirsvg = os.path.join(out_dir, 'heatmap.svg')\n",
    "save_dirpng = os.path.join(out_dir, 'heatmap.png')\n",
    "fig.savefig(save_dirsvg)\n",
    "fig.savefig(save_dirpng)\n",
    "print(f'Fig saved to ', save_dirpng)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate ROIs from a CSV of Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.generate_nifti import read_coordinates_csv\n",
    "\n",
    "coordinates_df = read_coordinates_csv(filename=path_1, radius=3)\n",
    "coordinates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates_df.to_csv(out_dir+'/coordinates_df.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate BIDS Directory from Subjects/Coordinates CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.generate_nifti import read_subject_coordinates_csv\n",
    "\n",
    "file_path_df = read_subject_coordinates_csv('/Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/VOSS_TMS/Memory_Change_TMS_SimonKwon_to_CalvinHoward.csv', radius=12, method='concentric')\n",
    "file_path_df.to_csv('/Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/VOSS_TMS/Memory_Change_TMS_SimonKwon_to_CalvinHoward' + '_filepaths.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Several Niftis Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.generate_nifti import add_matrices_together\n",
    "from calvin_utils.generate_nifti import view_and_save_nifti\n",
    "\n",
    "summed_matrix = add_matrices_together(folder=path_1)\n",
    "summed_matrix_img = view_and_save_nifti(summed_matrix, out_dir=path_1)\n",
    "summed_matrix_img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold a Matrix By another Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_1 = '/Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/BIDS_AD_DBS_FORNIX/derivatives/r_maps/r_map/Age/age_to_grey_matter.nii'\n",
    "path_2 = '/Users/cu135/Dropbox (Partners HealthCare)/resources/mni_spaces/6th_gen/mni_152_gm_mask_resampled.nii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.nifti_utils.generate_nifti import threshold_matrix_by_another\n",
    "thresholded_matrix = threshold_matrix_by_another(matrix_file_1=path_1, matrix_file_2=path_1, method='over_threshold', threshold=0.2)\n",
    "thresholded_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thresholding Matrices with the threshold_matrix Function\n",
    "Introduction\n",
    "_____\n",
    "Matrix thresholding is a common operation in many scientific applications, especially in fields like neuroscience and image processing. The threshold_matrix function provides a flexible way to threshold matrices based on different criteria.\n",
    "\n",
    "Key Functionalities\n",
    "Direction of Thresholding:\n",
    "\n",
    "Keep values above a certain threshold.\n",
    "Keep values below a certain threshold.\n",
    "Keep values between two thresholds.\n",
    "Methods to Determine the Threshold:\n",
    "\n",
    "Raw values.\n",
    "Z-score (probability-based).\n",
    "Percentile of the matrix values.\n",
    "Setting the Thresholded Values:\n",
    "\n",
    "To zero.\n",
    "To NaN (Not a Number).\n",
    "\n",
    "Usage\n",
    "Basic Syntax:\n",
    "python\n",
    "Copy code\n",
    "threshold_matrix(matrix, threshold, method, direction, output)\n",
    "```\n",
    "Parameters:\n",
    "matrix (np.array): The input matrix you want to threshold.\n",
    "threshold (float or tuple): The threshold value(s). If a tuple, interpreted as range.\n",
    "method (str): How to determine the threshold. Can be 'raw', 'probability', or 'percentile'.\n",
    "direction (str or tuple): Can be 'keep_above', 'keep_below', 'keep_between', 'exclude_between' or a tuple for a range (e.g., (5, 95)).\n",
    "output (str): What to set the thresholded values to. Can be 'zero' or 'nan'.\n",
    "```\n",
    "____\n",
    "Examples\n",
    "\n",
    "Keep values above a raw threshold of 0.5 and set the rest to NaN:\n",
    "python\n",
    "Copy code\n",
    "result = threshold_matrix(your_matrix, threshold=0.5, method='raw', direction='keep_above', output='nan')\n",
    "\n",
    "Keep values between the 5th and 95th percentiles of the matrix and set the rest to 0:\n",
    "python\n",
    "Copy code\n",
    "result = threshold_matrix(your_matrix, threshold=(5, 95), method='percentile', direction=(5, 95), output='zero')\n",
    "\n",
    "Keep values below a z-score threshold of 0.05 (using probability) and set the rest to 0:\n",
    "python\n",
    "Copy code\n",
    "result = threshold_matrix(your_matrix, threshold=0.05, method='probability', direction='keep_below', output='zero')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '/Users/cu135/Dropbox (Partners HealthCare)/resources/published_networks/reich_2022_thresholded'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fisher_transform = True\n",
    "# #Fisher transform \n",
    "# from calvin_utils.statistical_utils.fisher_z_transform import fisher_z_transform\n",
    "# if fisher_transform: \n",
    "#     df_1 = fisher_z_transform(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.nifti_utils.matrix_utilities import threshold_matrix\n",
    "from calvin_utils.nifti_utils.generate_nifti import view_and_save_nifti\n",
    "\n",
    "thresholded_df_1 = threshold_matrix(df_1, threshold=95, method='percentile', direction='keep_above', output='zero', mask_mode=False)\n",
    "threhsodled_matrix_img = view_and_save_nifti(thresholded_df_1, out_dir=out_dir)\n",
    "threhsodled_matrix_img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Matrix from a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nimlab import datasets as nimds\n",
    "\n",
    "data_df = pd.read_csv(path_2)\n",
    "if len(data_df) == 225222:\n",
    "    mni_mask = nimds.get_img(\"mni_icbm152\")\n",
    "    mask_data = mni_mask.get_fdata().flatten()\n",
    "    brain_indices = np.where(mask_data > 0)[0]\n",
    "    mask_data[brain_indices] = data_df.iloc[:,-1]\n",
    "    data_df = pd.DataFrame(mask_data)\n",
    "display(data_df)\n",
    "print(np.min(data_df))\n",
    "print(np.max(data_df))\n",
    "\n",
    "# data_df = (1/data_df)/10000\n",
    "# data_df = data_df/np.max(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.generate_nifti import view_and_save_nifti\n",
    "matrix_img = view_and_save_nifti(data_df, out_dir)\n",
    "matrix_img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Z-Scores for VBM Atrophy Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from nilearn import datasets\n",
    "from nilearn import image\n",
    "def threshold_probabilities(patient_df: pd.DataFrame, threshold: float) -> pd.DataFrame:\n",
    "    patient_df = patient_df.where(patient_df > threshold, 0)\n",
    "    return patient_df\n",
    "\n",
    "def calculate_z_scores(control_df: pd.DataFrame, patient_df: pd.DataFrame, matter_type=None) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Function to calculate voxel-wise mean, standard deviation for control group and z-scores for patient group.\n",
    "\n",
    "    Args:\n",
    "    control_df (pd.DataFrame): DataFrame where each column represents a control subject, \n",
    "                               and each row represents flattened image data for a voxel.\n",
    "    patient_df (pd.DataFrame): DataFrame where each column represents a patient, \n",
    "                               and each row represents flattened image data for a voxel.\n",
    "\n",
    "    Returns:\n",
    "    control_mean (pd.DataFrame): DataFrame of voxel-wise means calculated across the control group.\n",
    "    control_std (pd.DataFrame): DataFrame of voxel-wise standard deviations calculated across the control group.\n",
    "    patient_z_scores (pd.DataFrame): DataFrame of voxel-wise z-scores calculated for each patient using control mean and std.\n",
    "    \"\"\"\n",
    "\n",
    "    # Mask the dataframes to only consider tissues over acceptable probability thresholds\n",
    "    # Using p>0.2, as typical masking to MNI152 segments uses P > 0.2 for a given segment\n",
    "    \n",
    "    # Now you can use the function to apply a threshold to patient_df and control_df\n",
    "    threshold = 0.2\n",
    "    patient_df = threshold_probabilities(patient_df, threshold)\n",
    "    control_df = threshold_probabilities(control_df, threshold)\n",
    "\n",
    "    # Calculate mean and standard deviation for each voxel in control group\n",
    "    control_mean = control_df.mean(axis=1)\n",
    "    control_std = control_df.std(axis=1)\n",
    "\n",
    "    # Initialize DataFrame to store patient z-scores\n",
    "    patient_z_scores = pd.DataFrame()\n",
    "\n",
    "    # Calculate z-scores for each patient using control mean and std\n",
    "    for patient in patient_df.columns:\n",
    "        patient_z_scores[patient] = (patient_df[patient] - control_mean) / control_std\n",
    "\n",
    "    # Set values back into brain_mask\n",
    "    # if matter_type == None:\n",
    "    mni_mask = nimds.get_img(\"mni_icbm152\")\n",
    "    mask_data = mni_mask.get_fdata().flatten()\n",
    "    apply_mask = lambda patient_z_scores: np.where(mask_data > 0, patient_z_scores, 0)\n",
    "    patient_z_scores = patient_z_scores.apply(apply_mask, axis=0)\n",
    "    print('Not sure what matter class to mask to, returning mask within MNI152 space')\n",
    "    # elif matter_type == 'grey_matter':\n",
    "    #     mask_data = image.load_img('/Users/cu135/Dropbox (Partners HealthCare)/resources/mni_spaces/6th_gen/mni_152_gm_mask_resampled.nii').get_fdata().flatten()\n",
    "    #     patient_z_scores[mask_data < 0.2] = 0\n",
    "    #     print('Masked to MNI152 Grey Matter')\n",
    "    # elif matter_type == 'white_matter':\n",
    "    #     mask_data = image.load_img('/Users/cu135/Dropbox (Partners HealthCare)/resources/mni_spaces/6th_gen/mni_152_wm_mask_resampled.nii').get_fdata().flatten()\n",
    "    #     patient_z_scores[mask_data < 0.2] = 0\n",
    "    #     print('Masked to MNI152 White matter')\n",
    "    # elif matter_type == 'CSF':\n",
    "    #     mni_mask = nimds.get_img(\"mni_icbm152\")\n",
    "    #     mask_data = mni_mask.get_fdata().flatten()\n",
    "    #     apply_mask = lambda patient_z_scores: np.where(mask_data > 0.2, patient_z_scores, 0)\n",
    "    #     patient_z_scores = patient_z_scores.apply(apply_mask, axis=0)\n",
    "    #     print('Masking within the MNI brain mask')\n",
    "    # else:\n",
    "    #     raise ValueError('Please select a valid matter_type: None, grey_matter, white_matter are currently supported')\n",
    "\n",
    "    \n",
    "    return control_mean, control_std, patient_z_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matter_type = 'csf'\n",
    "\n",
    "#----------------------------------------------------------------DO NOT TOUCH ----------------------------------------------------------------\n",
    "\n",
    "control_mean, control_std, patient_z_score_df = calculate_z_scores(control_df=df_2, patient_df=df_1, matter_type=matter_type)\n",
    "\n",
    "# Plot pairplot and display descriptive statistics\n",
    "# print(patient_z_score_df.describe())\n",
    "display(patient_z_score_df)\n",
    "# patient_z_score_df.to_csv(os.path.join(out_dir, 'z_scores.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the atrophy files\n",
    "character_after_subject_id = '-'\n",
    "#--------------------------------DO NOT TOUCH--------------------------------------------------------\n",
    "from calvin_utils.generate_nifti import nifti_from_matrix\n",
    "root_dir = out_dir\n",
    "for patient in patient_z_score_df.columns:\n",
    "    subject = patient.split(character_after_subject_id)[0]\n",
    "    out_dir = os.path.join(root_dir, ('sub-'+subject+f'/z_score_atrophy/{matter_type}'))\n",
    "    nifti_from_matrix(patient_z_score_df[patient], output_file=out_dir, output_name=f'sub-{subject}')\n",
    "    \n",
    "    # /Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/BIDS_AD_DBS_FORNIX/rawdata/sub-150/ses-01/anat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Z-Scores for Atrophy ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def compute_roi_z_scores(path_atrophy, path_control):\n",
    "    \"\"\"\n",
    "    Function to compute z-scores for all brain regions for atrophy patients\n",
    "    in comparison to control group.\n",
    "\n",
    "    Parameters:\n",
    "    - path_atrophy: str, path to csv file for atrophy patients\n",
    "    - path_control: str, path to csv file for control group\n",
    "\n",
    "    Returns:\n",
    "    - df_atrophy_z_scored: DataFrame, atrophy patients data with z-scores in place of original values\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the data\n",
    "    df_atrophy = pd.read_csv(path_atrophy)\n",
    "    df_control = pd.read_csv(path_control)\n",
    "\n",
    "    # Create a copy of df_atrophy to hold the z-scored data\n",
    "    df_atrophy_z_scored = df_atrophy.copy()\n",
    "\n",
    "    # Loop over all columns (brain regions) in the dataframe\n",
    "    for column in tqdm(df_atrophy.columns):\n",
    "        \n",
    "        # Skip if the column is 'names'\n",
    "        if column == 'names':\n",
    "            continue\n",
    "        else:\n",
    "            # Compute the mean and standard deviation of the control group for the current brain region\n",
    "            control_mean = df_control[column].mean()\n",
    "            control_std = df_control[column].std()\n",
    "\n",
    "            # Calculate the z-scores for the atrophy patients relative to the control group\n",
    "            df_atrophy_z_scored[column] = df_atrophy[column].apply(lambda x: (x - control_mean) / control_std)\n",
    "\n",
    "    # Set the index to 'names'\n",
    "    df_atrophy_z_scored.set_index('names', inplace=True)\n",
    "\n",
    "    return df_atrophy_z_scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_1 = r'/Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/BIDS_PD_DBS_STN_WURZBURG/cat12/ROI_mni_Cerebellum_Vgm.csv'\n",
    "path_2 = r'/Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/ADNI/NIFTIS/true_control/cat_12_results/roi_volumes/ROI_mni_Cerebellum_Vgm.csv'\n",
    "roi_name = 'Cerebellum'\n",
    "roi_tissue = 'Vgm'\n",
    "#----------------------------------------------------------------DO NOT CHANGE\n",
    "df_atrophy_z_scored = compute_roi_z_scores(path_1, path_2)\n",
    "display(df_atrophy_z_scored)\n",
    "df_atrophy_z_scored.to_csv(os.path.join(out_dir + f'/{roi_name}_{roi_tissue}_z_scores.csv'))\n",
    "print('saved to: ', out_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract XML File Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "def parse_xml(file_path):\n",
    "    # Parse XML file\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # Find required tags and extract data\n",
    "    for memory_roi in root.findall('memory_roi'):\n",
    "        Vgm = memory_roi.find('data/Vgm').text\n",
    "        Vwm = memory_roi.find('data/Vwm').text\n",
    "        Vcsf = memory_roi.find('data/Vcsf').text\n",
    "        \n",
    "        return Vgm, Vwm, Vcsf\n",
    "\n",
    "def extract_data_from_xmls(directory):\n",
    "    # Create an empty dataframe\n",
    "    data = pd.DataFrame(columns=['Patient_ID', 'GM', 'WM', 'CSF'])\n",
    "    \n",
    "    # Walk through the directory\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.xml'):\n",
    "                patient_id = os.path.splitext(file)[0]  # Use filename as patient ID\n",
    "                file_path = os.path.join(root, file)\n",
    "                \n",
    "                Vgm, Vwm, Vcsf = parse_xml(file_path)\n",
    "                data = data.append({'Patient_ID': patient_id, 'GM': Vgm, 'WM': Vwm, 'CSF': Vcsf}, ignore_index=True)\n",
    "                \n",
    "    return data\n",
    "\n",
    "# Directory containing XML files\n",
    "directory = '/Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/BIDS_AD_DBS_FORNIX/cat12/cat12_ultrafine-reg/CAT12.8.2_2170'\n",
    "\n",
    "# Extract data and save to CSV\n",
    "data = extract_data_from_xmls(directory)\n",
    "# data.to_csv('patient_data.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import datasets\n",
    "# Fetch the MNI152 1mm white matter mask\n",
    "white_matter_mask = datasets.load_mni152_wm_mask(resolution=2)\n",
    "\n",
    "# Example usage\n",
    "mask_data = white_matter_mask.get_fdata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_matter_mask = datasets.load_mni152_gm_template(resolution=2)\n",
    "gray_matter_mask.to_filename('/Users/cu135/Dropbox (Partners HealthCare)/resources/mni_spaces/6th_gen/mni_152_gm_mask.nii')\n",
    "\n",
    "w_matter_mask = datasets.load_mni152_wm_template(resolution=2)\n",
    "w_matter_mask.to_filename('/Users/cu135/Dropbox (Partners HealthCare)/resources/mni_spaces/6th_gen/mni_152_wm_mask.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "mask_data = image.load_img('/Users/cu135/Dropbox (Partners HealthCare)/resources/mni_spaces/6th_gen/mni_152_gm_mask_resampled.nii')\n",
    "plotting.view_img(mask_data, cut_coords=(0,0,0), black_bg=False, opacity=.75, cmap='ocean_hot')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gray_matter_mask = datasets.load_mni152_gm_template(resolution=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power Analysis of Overlap R Map Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "n_voxels = 200000  # number of voxels per map\n",
    "n_iterations = 10000  # number of iterations\n",
    "threshold = 0.3  # threshold for overlap\n",
    "np.random.seed(0)  # set seed for reproducibility\n",
    "\n",
    "# store results\n",
    "results = {}\n",
    "\n",
    "for n_maps in range(2, 14):  # for each number of maps from 2 to 5\n",
    "    overlaps = 0  # counter for number of overlaps\n",
    "    pbar = tqdm(total=n_iterations, desc=f'Processing {n_maps} maps')\n",
    "    for _ in range(n_iterations):\n",
    "        # generate n_maps random maps\n",
    "        maps = [np.random.normal(0, 0.2, n_voxels) for _ in range(n_maps)]\n",
    "        # check if there's an overlap\n",
    "        if np.any(np.all([np.abs(map) > threshold for map in maps], axis=0)):\n",
    "            overlaps += 1\n",
    "        pbar.update()\n",
    "    pbar.close()\n",
    "    false_positive_rate = overlaps / n_iterations\n",
    "    results[n_maps] = false_positive_rate\n",
    "\n",
    "# print results\n",
    "for n_maps, rate in results.items():\n",
    "    print(f'False positive rate for {n_maps} maps: {rate}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Damage Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "damaging_thing = 'grey_matter'\n",
    "things_damaged = 'hippocampus'\n",
    "descriptor = 'all_patient'\n",
    "#----------------------------------------------------------------DO NOT MODIFY!----------------------------------------------------------------\n",
    "#Initialize dataframe\n",
    "damage_df = pd.DataFrame(index=df_1.columns, columns=df_2.columns)\n",
    "\n",
    "for matrix in damage_df.columns:\n",
    "    for subject in damage_df.index:\n",
    "        # Mask the subject dataframe to the matrix at hand\n",
    "        intersection = df_1[subject].where(df_2[matrix] > 0, 0)\n",
    "        # Weight the overlapping components by multiplication\n",
    "        weighted_overlap = intersection * df_2[matrix]\n",
    "        # Assess overall damage score\n",
    "        damage = weighted_overlap.sum()\n",
    "        damage_df.loc[subject, matrix] = damage\n",
    "\n",
    "if not os.path.exists(out_dir + '/damage_scores'):\n",
    "    os.makedirs(out_dir + '/damage_scores')\n",
    "\n",
    "damage_df.to_csv(out_dir + f'/damage_scores/{descriptor}_{things_damaged}_damage_scores_{damaging_thing}.csv')\n",
    "print('saved to: ', out_dir + f'/damage_scores/{descriptor}_{things_damaged}_damage_scores_{damaging_thing}.csv')\n",
    "\n",
    "display(damage_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename Niftis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "filename = 'mwp1glanat.nii'\n",
    "base_dir = '/Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/BIDS_PD_DBS_STN_WURZBURG/neuroimaging'\n",
    "folder_to_name_by = -4\n",
    "save = True\n",
    "\n",
    "#----------------------------------------------------------------DO NOT MODIFY!----------------------------------------------------------------\n",
    "\n",
    "# Use glob to find all mwp1glanat.nii files with incorrect names\n",
    "file_paths = glob.glob(os.path.join(base_dir, '**', 'mwp1glanat_resampled.nii'), recursive=True)\n",
    "print(file_paths)\n",
    "for file_path in file_paths:\n",
    "    # Print the found file\n",
    "    print(f'Found file: {file_path}')\n",
    "    \n",
    "    # Extract the sub-id\n",
    "    sub_id = file_path.split(os.sep)[folder_to_name_by]\n",
    "    print(f'Extracted sub-id: {sub_id}')\n",
    "\n",
    "    # Construct the new file path\n",
    "    new_file_path = os.path.join(os.path.dirname(file_path), f'{sub_id}-{filename}')\n",
    "    print(f'Intended absolute filename: {new_file_path}')\n",
    "    if save:\n",
    "        shutil.copy(file_path, new_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimlab_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62880161f19d28ddb8a8f59c63374d84ace356c39e36cc839cb3fb3bb03fb010"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
